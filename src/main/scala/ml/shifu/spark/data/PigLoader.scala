package ml.shifu.spark.data

import ml.shifu.shifu.container.obj.ColumnConfig
import org.apache.spark.sql.types.{DataType, StructField, StructType}
import org.apache.spark.sql.{DataFrame, Dataset, SQLContext, SparkSession}

import scala.util.parsing.json._

/**
  * Created by Mark on 6/2/2017.
  */
class PigLoader(sparkSession:SparkSession, columnConfigList:Seq[ColumnConfig], path:String) {

  def sc = sparkSession.sparkContext

  def load() : DataFrame = {
    val schema = loadSchema()
    val df = sparkSession.read.format("csv")
                         .schema(new StructType(schema.map(s => new StructField(s._1, DataType.))))
  }

  private def loadSchema() = {
    columnConfigList.filter(c => c.isFinalSelect)
                    .map(c => Pair(c.getColumnName, c.getColumnType))
  }

}

object PigLoader {

  def data =
    """{"fields":[
      |{"name":"VID","type":55,"description":"autogenerated from Pig Field Schema","schema":null},
      |{"name":"version","type":55,"description":"autogenerated from Pig Field Schema","schema":null},
      |{"name":"MnNumAllTxn","type":25,"description":"autogenerated from Pig Field Schema","schema":null}
      |],"version":0,"sortKeys":[],"sortKeyOrders":[]}""".stripMargin

  def data2 = """{"field": [{"name":"123"}, {"name":"234"}, {"name":null}]}"""
  def main(args: Array[String]): Unit = {
    val schema = JSON.parseRaw(data).get
    print(schema)
  }
}


